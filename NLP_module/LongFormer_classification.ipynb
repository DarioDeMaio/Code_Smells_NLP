{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ID7T5RDUhHSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a1beece-02ab-42ce-f659-18714f8a4fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "id": "dIPMET94jBPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ed70048-2b5d-41a5-9c18-e4acfd776b56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "bKffIxY3LCHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b57078-a84c-45e9-b785-653f0ab4cc67"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n"
      ],
      "metadata": {
        "id": "ZahQ0GsPqM-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a631ab-d0fd-4713-9bb3-c2e888a009c9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import LongformerModel, AutoTokenizer\n",
        "import torch as pt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "import chardet\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, matthews_corrcoef, roc_auc_score\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "wkQ0Sz5OjCjB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/code smells tesi/projects\"\n",
        "projects = []\n",
        "code_smells = ['CDSBP', 'CC', 'LC', 'LZC', 'RB', 'SC']\n",
        "# Itera su tutti i file e le cartelle nella cartella specificata\n",
        "for item in os.listdir(path):\n",
        "    # Se l'elemento nella cartella Ã¨ una cartella, aggiungi il nome alla lista\n",
        "    if os.path.isdir(os.path.join(path, item)):\n",
        "       projects.append(item)\n",
        "    # Stampa la lista di nomi dei progetti\n",
        "print(projects)"
      ],
      "metadata": {
        "id": "lsj1nXzWyuhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b75137c1-33bb-4cfc-9bd9-4b447826ee15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ant-ivy-2.0.0-alpha2', 'ant-rel-1.8.3', 'cassandra-cassandra-1.0.0', 'elasticsearch-v0.19.0', 'hadoop-release-0.6.0', 'hive-release-0.9.0', 'hsqldb-2.2.8', 'karaf-karaf-2.3.0', 'lucene-releases-lucene-solr-3.6.0', 'manifold-cf-release-0.6', 'nutch-release-1.4', 'pig-release-0.8.0', 'qpid-0.14', 'struts-STRUTS_2_3_4', 'xerces2-j-Xerces-J_2_3_0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "projects = ['ant-ivy-2.0.0-alpha2', 'ant-rel-1.8.3', 'cassandra-cassandra-1.0.0', 'elasticsearch-v0.19.0', 'hadoop-release-0.6.0', 'hive-release-0.9.0', 'hsqldb-2.2.8', 'karaf-karaf-2.3.0']"
      ],
      "metadata": {
        "id": "uKJLC7pCmZyr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/code smells tesi/Code_Smells_NLP-Finale/dataset/ultimate_dataset.csv\")"
      ],
      "metadata": {
        "id": "rJsU045KjhJ-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "U2HSfOwej7hk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "outputId": "d8723ff3-5676-4455-da0b-a226308652d2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Project_name  \\\n",
              "0         ant-ivy-2.0.0-alpha2   \n",
              "1         ant-ivy-2.0.0-alpha2   \n",
              "2         ant-ivy-2.0.0-alpha2   \n",
              "3         ant-ivy-2.0.0-alpha2   \n",
              "4         ant-ivy-2.0.0-alpha2   \n",
              "...                        ...   \n",
              "8139  xerces2-j-Xerces-J_2_3_0   \n",
              "8140  xerces2-j-Xerces-J_2_3_0   \n",
              "8141  xerces2-j-Xerces-J_2_3_0   \n",
              "8142  xerces2-j-Xerces-J_2_3_0   \n",
              "8143  xerces2-j-Xerces-J_2_3_0   \n",
              "\n",
              "                                              Component   CBO  CYCLO  DIT  \\\n",
              "0     /*\\n *  Licensed to the Apache Software Founda...  41.0  136.0  1.0   \n",
              "1     /*\\n *  Licensed to the Apache Software Founda...  31.0  172.0  1.0   \n",
              "2     /*\\n *  Licensed to the Apache Software Founda...  43.0   35.0  1.0   \n",
              "3     /*\\n *  Licensed to the Apache Software Founda...   8.0   25.0  2.0   \n",
              "4     /*\\n *  Licensed to the Apache Software Founda...  16.0   26.0  2.0   \n",
              "...                                                 ...   ...    ...  ...   \n",
              "8139  /*\\n * The Apache Software License, Version 1....   4.0   25.0  2.0   \n",
              "8140  // XMLFilterImpl.java - base SAX2 filter imple...  14.0  120.0  1.0   \n",
              "8141  // XMLReaderAdapter.java - adapt an SAX2 XMLRe...  15.0   45.0  1.0   \n",
              "8142  // XMLReaderFactory.java - factory for creatin...   5.0   16.0  1.0   \n",
              "8143  // XMLReaderFactory.java - factory for creatin...   5.0   16.0  1.0   \n",
              "\n",
              "       ELOC   FanIn  FanOut    LCOM    LOC  ...   WLOCNAMM    WMC  WMCNAMM  \\\n",
              "0     346.0  2036.0    83.0  1482.0  346.0  ...   5.592593  136.0      0.0   \n",
              "1     221.0     0.0   207.0     0.0  221.0  ...   3.583333  172.0      0.0   \n",
              "2     295.0    20.0   121.0    45.0  295.0  ...  28.900000   35.0      0.0   \n",
              "3      59.0     0.0    11.0     0.0   59.0  ...   4.363636   25.0      0.0   \n",
              "4     101.0     2.0    37.0    44.0  101.0  ...   8.888889   26.0      0.0   \n",
              "...     ...     ...     ...     ...    ...  ...        ...    ...      ...   \n",
              "8139   55.0     5.0    15.0    28.0   55.0  ...   9.375000   25.0      0.0   \n",
              "8140  449.0     2.0    29.0   364.0  449.0  ...  12.548387  120.0      0.0   \n",
              "8141  279.0     2.0    20.0   115.0  279.0  ...   9.227273   45.0      0.0   \n",
              "8142   97.0    11.0    12.0     6.0   97.0  ...  22.000000   16.0      0.0   \n",
              "8143   97.0    11.0    12.0     6.0   97.0  ...  22.000000   16.0      0.0   \n",
              "\n",
              "      NMNOPARAM  CDSBP  CC  LC  LZC  RB  SC  \n",
              "0          23.0      0   0   0    0   0   0  \n",
              "1           6.0      0   0   0    0   0   0  \n",
              "2           2.0      0   0   0    0   0   0  \n",
              "3           5.0      0   0   0    0   0   0  \n",
              "4           4.0      0   0   0    0   0   0  \n",
              "...         ...    ...  ..  ..  ...  ..  ..  \n",
              "8139        5.0      0   0   0    0   0   0  \n",
              "8140        9.0      0   0   0    0   0   0  \n",
              "8141        4.0      0   0   0    0   0   0  \n",
              "8142        2.0      0   0   0    0   0   1  \n",
              "8143        2.0      0   0   0    0   0   1  \n",
              "\n",
              "[8144 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-72a82f08-c062-4e06-9c73-4d4fac0fff57\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Project_name</th>\n",
              "      <th>Component</th>\n",
              "      <th>CBO</th>\n",
              "      <th>CYCLO</th>\n",
              "      <th>DIT</th>\n",
              "      <th>ELOC</th>\n",
              "      <th>FanIn</th>\n",
              "      <th>FanOut</th>\n",
              "      <th>LCOM</th>\n",
              "      <th>LOC</th>\n",
              "      <th>...</th>\n",
              "      <th>WLOCNAMM</th>\n",
              "      <th>WMC</th>\n",
              "      <th>WMCNAMM</th>\n",
              "      <th>NMNOPARAM</th>\n",
              "      <th>CDSBP</th>\n",
              "      <th>CC</th>\n",
              "      <th>LC</th>\n",
              "      <th>LZC</th>\n",
              "      <th>RB</th>\n",
              "      <th>SC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
              "      <td>41.0</td>\n",
              "      <td>136.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>2036.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>1482.0</td>\n",
              "      <td>346.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.592593</td>\n",
              "      <td>136.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
              "      <td>31.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>207.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.583333</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
              "      <td>43.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>121.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>295.0</td>\n",
              "      <td>...</td>\n",
              "      <td>28.900000</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.363636</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>/*\\n *  Licensed to the Apache Software Founda...</td>\n",
              "      <td>16.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8.888889</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8139</th>\n",
              "      <td>xerces2-j-Xerces-J_2_3_0</td>\n",
              "      <td>/*\\n * The Apache Software License, Version 1....</td>\n",
              "      <td>4.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>55.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.375000</td>\n",
              "      <td>25.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8140</th>\n",
              "      <td>xerces2-j-Xerces-J_2_3_0</td>\n",
              "      <td>// XMLFilterImpl.java - base SAX2 filter imple...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>364.0</td>\n",
              "      <td>449.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.548387</td>\n",
              "      <td>120.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8141</th>\n",
              "      <td>xerces2-j-Xerces-J_2_3_0</td>\n",
              "      <td>// XMLReaderAdapter.java - adapt an SAX2 XMLRe...</td>\n",
              "      <td>15.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>279.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.227273</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8142</th>\n",
              "      <td>xerces2-j-Xerces-J_2_3_0</td>\n",
              "      <td>// XMLReaderFactory.java - factory for creatin...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8143</th>\n",
              "      <td>xerces2-j-Xerces-J_2_3_0</td>\n",
              "      <td>// XMLReaderFactory.java - factory for creatin...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>97.0</td>\n",
              "      <td>...</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8144 rows Ã 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72a82f08-c062-4e06-9c73-4d4fac0fff57')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2650d7af-110c-4a04-aa77-7a091b6baa1f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2650d7af-110c-4a04-aa77-7a091b6baa1f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2650d7af-110c-4a04-aa77-7a091b6baa1f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72a82f08-c062-4e06-9c73-4d4fac0fff57 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72a82f08-c062-4e06-9c73-4d4fac0fff57');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for x in df['Component']:\n",
        "  parole = x.split()\n",
        "  if(len(parole)>1024):\n",
        "    c +=1\n",
        "print(c)"
      ],
      "metadata": {
        "id": "-G4h2Fkix7P6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2b6f96-9876-4c23-8357-6c339a13c837"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# nltk.download('stopwords')\n",
        "\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# def remove_comments(code):\n",
        "#     # Rimuove i commenti su una singola riga\n",
        "#     code = re.sub(r'//.*', '', code)\n",
        "#     # Rimuove i commenti su piÃ¹ righe\n",
        "#     code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
        "#     # Rimuove le stopwords\n",
        "#     tokens = [word.lower() for word in code.split() if word.lower() not in stop_words]\n",
        "#     filtered_text = ' '.join(tokens)\n",
        "#     # Rimuoviamo gli import\n",
        "#     code = re.sub(r'import\\s+.*?;', '', code, flags=re.DOTALL)\n",
        "#     # Rimuoviamo i package\n",
        "#     code = re.sub(r'package\\s+.*?;', '', code, flags=re.DOTALL)\n",
        "#     #Rimuove \\n e \\t\n",
        "#     code = re.sub(r'[\\n\\t]', '', code)\n",
        "#     return code\n",
        "\n",
        "# for i in range(len(df)):\n",
        "#     df['Component'][i] = remove_comments(df['Component'][i])\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Aggiungi stopwords specifiche per Java\n",
        "java_stopwords = [\n",
        "    'java', 'protected', 'class', 'interface', 'package',\n",
        "    'import', 'static', 'void', 'new', 'return', 'extends', 'implements', 'null',\n",
        "    'try', 'catch', 'finally', 'throw', 'throws'\n",
        "]\n",
        "\n",
        "stop_words.update(java_stopwords)\n",
        "\n",
        "def remove_comments(code):\n",
        "    # Rimuove i commenti su una singola riga\n",
        "    code = re.sub(r'//.*', '', code)\n",
        "    # Rimuove i commenti su piÃ¹ righe\n",
        "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
        "    # Rimuoviamo gli import\n",
        "    code = re.sub(r'import\\s+.*?;', '', code, flags=re.DOTALL)\n",
        "    # Rimuoviamo i package\n",
        "    code = re.sub(r'package\\s+.*?;', '', code, flags=re.DOTALL)\n",
        "    # Rimuove \\n e \\t\n",
        "    code = re.sub(r'[\\n\\t]', '', code)\n",
        "    # Rimuove le stopwords solo se sono parole singole\n",
        "    tokens = [word.lower() for word in code.split() if word.lower() not in stop_words]\n",
        "    filtered_text = ' '.join(tokens)\n",
        "    return filtered_text\n",
        "\n",
        "for i in range(len(df)):\n",
        "    df['Component'][i] = remove_comments(df['Component'][i])"
      ],
      "metadata": {
        "id": "qq1FfqzUXeZJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c994216-afd6-44db-b554-25f950ed5718"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-11-0bbbb70b7342>:54: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Component'][i] = remove_comments(df['Component'][i])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "pL0sg5TqKXlR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = 0\n",
        "for x in df['Component']:\n",
        "  parole = x.split()\n",
        "  if(len(parole)>1536):\n",
        "    c +=1\n",
        "print(c)"
      ],
      "metadata": {
        "id": "kZFb03t9xLt8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194fd4f6-d8f1-4cf6-bcc3-40e0c326bf1a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "def create_filtered_dataframe(input_dataframe, required_cols, num_instances=4000):\n",
        "    # Filtra le istanze con almeno un 1 nelle colonne richieste\n",
        "    filtered_df = input_dataframe[input_dataframe[required_cols].sum(axis=1) >= 1].copy()\n",
        "    # Verifica e rimuovi eventuali duplicati\n",
        "    filtered_df.drop_duplicates(inplace=True)\n",
        "    # Seleziona casualmente altre istanze con tutte le colonne a 0 senza duplicati\n",
        "    remaining_instances = num_instances - len(filtered_df)\n",
        "    if remaining_instances > 0:\n",
        "        zero_instances = input_dataframe[input_dataframe[required_cols].sum(axis=1) == 0]\n",
        "        if len(zero_instances) < remaining_instances:\n",
        "            raise ValueError(\"Non ci sono abbastanza istanze con tutte le colonne a 0.\")\n",
        "\n",
        "        # Rimuovi eventuali duplicati tra le istanze con tutte le colonne a 0\n",
        "        zero_instances = zero_instances.drop_duplicates()\n",
        "\n",
        "        # Seleziona casualmente le istanze con tutte le colonne a 0\n",
        "        random_zero_instances = zero_instances.sample(remaining_instances)\n",
        "        filtered_df = pd.concat([filtered_df, random_zero_instances])\n",
        "\n",
        "    # Riduci il dataframe alle prime 4000 istanze, se necessario\n",
        "    if len(filtered_df) > num_instances:\n",
        "        filtered_df = filtered_df.sample(num_instances)\n",
        "\n",
        "    # Reimposta gli indici in modo sequenziale a partire da 1\n",
        "    filtered_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    return filtered_df\n",
        "\n",
        "# Esempio di utilizzo:\n",
        "# Supponiamo che il tuo dataframe originale si chiami 'df'\n",
        "required_columns = ['CDSBP', 'CC', 'LC', 'LZC', 'RB', 'SC']\n",
        "dataframe = create_filtered_dataframe(df, required_columns)\n"
      ],
      "metadata": {
        "id": "RAKfqslfKfUm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "y6Vy_ZRIUio7",
        "outputId": "bb6a2f8a-ded2-4321-ebe8-5a612f8a8080"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   Project_name  \\\n",
              "0          ant-ivy-2.0.0-alpha2   \n",
              "1          ant-ivy-2.0.0-alpha2   \n",
              "2          ant-ivy-2.0.0-alpha2   \n",
              "3          ant-ivy-2.0.0-alpha2   \n",
              "4          ant-ivy-2.0.0-alpha2   \n",
              "...                         ...   \n",
              "3995      elasticsearch-v0.19.0   \n",
              "3996      elasticsearch-v0.19.0   \n",
              "3997              ant-rel-1.8.3   \n",
              "3998       ant-ivy-2.0.0-alpha2   \n",
              "3999  cassandra-cassandra-1.0.0   \n",
              "\n",
              "                                              Component   CBO  CYCLO  DIT  \\\n",
              "0     public ivybuildlist ivytask { private list bui...  26.0   68.0  2.0   \n",
              "1     public abstract ivypostresolvetask ivytask { p...  14.0   69.0  2.0   \n",
              "2     public ivypublish ivytask { private string org...  19.0   75.0  2.0   \n",
              "3     public ivyresolve ivytask { private file file ...  14.0   62.0  2.0   \n",
              "4     public ivynode comparable { private final patt...  37.0  229.0  1.0   \n",
              "...                                                 ...   ...    ...  ...   \n",
              "3995  public deleteindextemplateresponse actionrespo...   5.0   10.0  1.0   \n",
              "3996  public validateactions { public actionrequestv...   0.0    3.0  1.0   \n",
              "3997  public leadpipeinputstream pipedinputstream { ...   6.0   26.0  2.0   \n",
              "3998  public latestconflictmanager abstractconflictm...  10.0   23.0  2.0   \n",
              "3999  public jdbcuuid abstractjdbcuuid{ public final...   2.0    8.0  2.0   \n",
              "\n",
              "       ELOC  FanIn  FanOut    LCOM    LOC  ...   WLOCNAMM    WMC  WMCNAMM  \\\n",
              "0     306.0   21.0    96.0   389.0  306.0  ...  10.840000   68.0      0.0   \n",
              "1     258.0   25.0    85.0   526.0  258.0  ...   7.851852   69.0      0.0   \n",
              "2     313.0    4.0    64.0   769.0  313.0  ...   5.727273   75.0      0.0   \n",
              "3     240.0  115.0    52.0   583.0  240.0  ...   6.714286   62.0      0.0   \n",
              "4     834.0  194.0   317.0  3030.0  834.0  ...   9.180723  229.0      0.0   \n",
              "...     ...    ...     ...     ...    ...  ...        ...    ...      ...   \n",
              "3995   23.0   18.0     3.0     0.0   23.0  ...   2.833333   10.0      0.0   \n",
              "3996   11.0   10.0     1.0     0.0   11.0  ...   7.000000    3.0      0.0   \n",
              "3997  117.0    4.0     9.0    34.0  117.0  ...  12.111111   26.0      0.0   \n",
              "3998   96.0   13.0    26.0    12.0   96.0  ...   7.666667   23.0      0.0   \n",
              "3999   19.0    6.0     6.0     3.0   19.0  ...   5.333333    8.0      0.0   \n",
              "\n",
              "      NMNOPARAM  CDSBP  CC  LC  LZC  RB  SC  \n",
              "0          12.0      0   0   0    0   0   1  \n",
              "1          18.0      0   0   0    0   0   1  \n",
              "2          20.0      0   0   0    0   0   1  \n",
              "3          18.0      0   0   0    0   0   1  \n",
              "4          31.0      0   0   1    0   0   0  \n",
              "...         ...    ...  ..  ..  ...  ..  ..  \n",
              "3995        3.0      0   0   0    0   0   0  \n",
              "3996        0.0      0   0   0    0   0   0  \n",
              "3997        2.0      0   0   0    0   0   0  \n",
              "3998        3.0      0   0   0    0   0   0  \n",
              "3999        1.0      0   0   0    0   0   0  \n",
              "\n",
              "[4000 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7ee7f08e-e9b9-4e1a-8944-4956ab479e89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Project_name</th>\n",
              "      <th>Component</th>\n",
              "      <th>CBO</th>\n",
              "      <th>CYCLO</th>\n",
              "      <th>DIT</th>\n",
              "      <th>ELOC</th>\n",
              "      <th>FanIn</th>\n",
              "      <th>FanOut</th>\n",
              "      <th>LCOM</th>\n",
              "      <th>LOC</th>\n",
              "      <th>...</th>\n",
              "      <th>WLOCNAMM</th>\n",
              "      <th>WMC</th>\n",
              "      <th>WMCNAMM</th>\n",
              "      <th>NMNOPARAM</th>\n",
              "      <th>CDSBP</th>\n",
              "      <th>CC</th>\n",
              "      <th>LC</th>\n",
              "      <th>LZC</th>\n",
              "      <th>RB</th>\n",
              "      <th>SC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public ivybuildlist ivytask { private list bui...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>389.0</td>\n",
              "      <td>306.0</td>\n",
              "      <td>...</td>\n",
              "      <td>10.840000</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public abstract ivypostresolvetask ivytask { p...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>69.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>526.0</td>\n",
              "      <td>258.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.851852</td>\n",
              "      <td>69.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public ivypublish ivytask { private string org...</td>\n",
              "      <td>19.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>769.0</td>\n",
              "      <td>313.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.727273</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public ivyresolve ivytask { private file file ...</td>\n",
              "      <td>14.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>583.0</td>\n",
              "      <td>240.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6.714286</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public ivynode comparable { private final patt...</td>\n",
              "      <td>37.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>834.0</td>\n",
              "      <td>194.0</td>\n",
              "      <td>317.0</td>\n",
              "      <td>3030.0</td>\n",
              "      <td>834.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9.180723</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>elasticsearch-v0.19.0</td>\n",
              "      <td>public deleteindextemplateresponse actionrespo...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>elasticsearch-v0.19.0</td>\n",
              "      <td>public validateactions { public actionrequestv...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>ant-rel-1.8.3</td>\n",
              "      <td>public leadpipeinputstream pipedinputstream { ...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>117.0</td>\n",
              "      <td>...</td>\n",
              "      <td>12.111111</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>ant-ivy-2.0.0-alpha2</td>\n",
              "      <td>public latestconflictmanager abstractconflictm...</td>\n",
              "      <td>10.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7.666667</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>cassandra-cassandra-1.0.0</td>\n",
              "      <td>public jdbcuuid abstractjdbcuuid{ public final...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.333333</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4000 rows Ã 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ee7f08e-e9b9-4e1a-8944-4956ab479e89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-fafe3752-825b-4c2b-8ea4-546d1b938f79\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fafe3752-825b-4c2b-8ea4-546d1b938f79')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-fafe3752-825b-4c2b-8ea4-546d1b938f79 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ee7f08e-e9b9-4e1a-8944-4956ab479e89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ee7f08e-e9b9-4e1a-8944-4956ab479e89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AdamW\n",
        "\n",
        "code_smells = ['CC', 'LC']\n",
        "\n",
        "# Dataframe per i risultati finali\n",
        "CB_final_df = pd.DataFrame()\n",
        "\n",
        "# Dizionario per salvare le predizioni\n",
        "CB_predictions = {}\n",
        "\n",
        "# Dizionario per salvare le metriche\n",
        "CB_metrics = {}\n",
        "\n",
        "# Loop attraverso i progetti\n",
        "for project in projects:\n",
        "    print(\"Current project:\", project)\n",
        "\n",
        "    # Caricamento dei dati specifici del progetto\n",
        "    project_df = dataframe[dataframe['Project_name'] == project]\n",
        "    if len(project_df) == 0:\n",
        "        continue\n",
        "\n",
        "    # Inizializza i dizionari per il progetto corrente\n",
        "\n",
        "    CB_predictions[project] ={}\n",
        "    CB_metrics[project] ={}\n",
        "\n",
        "    # Loop attraverso i code smell\n",
        "    for smell in code_smells:\n",
        "        print(\"Current code smell:\", smell)\n",
        "\n",
        "        X = project_df.drop(columns=['CDSBP', 'CC', 'LC', 'LZC', 'RB', 'SC'])\n",
        "        y = project_df[str(smell)]\n",
        "\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "        ##\n",
        "        c = 0\n",
        "        for x in Y_test:\n",
        "          if(x == 1):\n",
        "            c += 1\n",
        "        if(c < 2):\n",
        "          continue\n",
        "\n",
        "        #Dati per CodeBert\n",
        "        X_train_comp = X_train['Component']\n",
        "        X_test_comp = X_test['Component']\n",
        "\n",
        "        # Fitting vari modelli\n",
        "\n",
        "        # Caricamento del tokenizer e del modello pre-addestrato CodeBERT\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "        model = AutoModelForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=1)\n",
        "\n",
        "        # Tokenizzazione del set di addestramento\n",
        "        train_encodings = tokenizer(list(X_train_comp), truncation=True, padding=True, max_length = 1024)\n",
        "        train_labels = pt.tensor(Y_train.values)\n",
        "        # Tokenizzazione del set di test\n",
        "        test_encodings = tokenizer(list(X_test_comp), truncation=True, padding=True, max_length = 1024)\n",
        "        test_labels = pt.tensor(Y_test.values)\n",
        "\n",
        "        # Inizio training\n",
        "\n",
        "\n",
        "        # Imposta la dimensione del batch desiderata\n",
        "        batch_size = 5\n",
        "\n",
        "        # Definizione del dispositivo (GPU o CPU)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Conversione dei dati tokenizzati in tensori PyTorch\n",
        "        train_inputs = torch.tensor(train_encodings['input_ids']).to(device)\n",
        "        train_labels = torch.tensor(Y_train.values).unsqueeze(1).to(device)\n",
        "\n",
        "        val_inputs = torch.tensor(test_encodings['input_ids']).to(device)\n",
        "        val_labels = torch.tensor(Y_test.values).unsqueeze(1).to(device)\n",
        "\n",
        "        # Creazione del dataset di addestramento\n",
        "        train_dataset = TensorDataset(train_inputs, train_labels)\n",
        "\n",
        "        # Creazione del dataset di validazione\n",
        "        val_dataset = TensorDataset(val_inputs, val_labels)\n",
        "\n",
        "        # Crea i dataloader con la nuova batch_size\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "        # Creazione dell'ottimizzatore\n",
        "        optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "        # Definizione della funzione di perdita\n",
        "        loss_function = loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "        # Addestramento del modello\n",
        "        model.to(device)\n",
        "        model.train()\n",
        "\n",
        "        for epoch in range(3):\n",
        "            for batch in train_dataloader:\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                inputs = batch[0].to(device)\n",
        "                labels = batch[1].to(device)\n",
        "                labels = labels.float()\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                logits = outputs.logits\n",
        "\n",
        "                loss = loss_function(logits.squeeze(), labels.squeeze())  # Calcola la loss tra logits e etichette\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                #print(f\"Epoch {epoch+1} - Loss: {loss.item()}\")\n",
        "                # Libera la memoria GPU\n",
        "                del inputs, labels\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Fine training\n",
        "        predictions = []\n",
        "        torch.cuda.empty_cache()\n",
        "        for batch in val_dataloader:\n",
        "            inputs = batch[0].to(device)\n",
        "            labels = batch[1].to(device)\n",
        "\n",
        "            val_outputs = model(inputs)\n",
        "            val_predicted_labels = (val_outputs.logits.sigmoid().squeeze() > 0.5).int()\n",
        "\n",
        "            if val_predicted_labels.dim() > 0:  # Verifica la dimensione del tensore\n",
        "              predictions.extend(val_predicted_labels.cpu().numpy())\n",
        "\n",
        "            del inputs, labels, val_outputs, val_predicted_labels\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        predictions = np.array(predictions)\n",
        "        test_labels = test_labels.cpu().numpy()\n",
        "\n",
        "        precision = precision_score(test_labels, predictions, average='macro')\n",
        "        accuracy = accuracy_score(test_labels, predictions)\n",
        "        mcc = matthews_corrcoef(test_labels, predictions)\n",
        "        recall = recall_score(test_labels, predictions, average='macro')\n",
        "        f1 = f1_score(test_labels, predictions, average='macro')\n",
        "        print(\"Precision\",precision)\n",
        "        print(\"F1\", f1)\n",
        "        print(\"MCC\", mcc)\n",
        "        CB_metrics[project][smell] = {\n",
        "            \"Precision\": precision,\n",
        "            \"Accuracy\": accuracy,\n",
        "            \"Recall\": recall,\n",
        "            \"F1\": f1,\n",
        "            \"MCC\": mcc\n",
        "        }\n",
        "\n",
        "        CB_predictions[project][smell] = predictions\n",
        "\n",
        "        del predictions\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "        CB_temp_pred = pd.DataFrame({\n",
        "            'Project_name': [project],\n",
        "            'Smell': [smell],\n",
        "            'Y_pred': [CB_predictions[project][smell].tolist()],\n",
        "            'Y_test': [Y_test.tolist()],\n",
        "            'precision': precision,\n",
        "            'accuracy': accuracy,\n",
        "            'recall': recall,\n",
        "            'f1': f1,\n",
        "            'mcc': mcc,\n",
        "        })\n",
        "\n",
        "        CB_final_df = pd.concat([CB_final_df, CB_temp_pred], ignore_index=True)\n",
        "\n",
        "CB_final_df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/code smells tesi/Code_Smells_NLP-Finale/LF_results.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "t-RtjHUBwyF4",
        "outputId": "65beeb4f-a8e5-4601-e98d-7008835465c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current project: ant-ivy-2.0.0-alpha2\n",
            "Current code smell: CC\n",
            "Current code smell: LC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.4838709677419355\n",
            "F1 0.4918032786885246\n",
            "MCC 0.0\n",
            "Current project: ant-rel-1.8.3\n",
            "Current code smell: CC\n",
            "Current code smell: LC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.49473684210526314\n",
            "F1 0.4973544973544973\n",
            "MCC 0.0\n",
            "Current project: cassandra-cassandra-1.0.0\n",
            "Current code smell: CC\n",
            "Current code smell: LC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.48623853211009177\n",
            "F1 0.4930232558139535\n",
            "MCC 0.0\n",
            "Current project: elasticsearch-v0.19.0\n",
            "Current code smell: CC\n",
            "Current code smell: LC\n",
            "Current project: hadoop-release-0.6.0\n",
            "Current code smell: CC\n",
            "Current code smell: LC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.4787234042553192\n",
            "F1 0.4891304347826087\n",
            "MCC 0.0\n",
            "Current project: hive-release-0.9.0\n",
            "Current project: hsqldb-2.2.8\n",
            "Current code smell: CC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision 0.491869918699187\n",
            "F1 0.4959016393442623\n",
            "MCC 0.0\n",
            "Current code smell: LC\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-256cd379722c>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m             \u001b[0mval_predicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1931\u001b[0m             \u001b[0mglobal_attention_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m         outputs = self.longformer(\n\u001b[0m\u001b[1;32m   1934\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1744\u001b[0m         )\n\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1746\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1747\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1748\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1321\u001b[0m                 )\n\u001b[1;32m   1322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m   1324\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1244\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     ):\n\u001b[0;32m-> 1246\u001b[0;31m         self_attn_outputs = self.attention(\n\u001b[0m\u001b[1;32m   1247\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m     ):\n\u001b[0;32m-> 1182\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/longformer/modeling_longformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;31m# softmax sometimes inserts NaN if all positions are masked, replace them with 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mattn_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_index_masked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mattn_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_probs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 122.00 MiB (GPU 0; 14.75 GiB total capacity; 13.54 GiB already allocated; 12.81 MiB free; 13.96 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from transformers import AdamW\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "# import torch.nn as nn\n",
        "# from sklearn.metrics import accuracy_score, precision_score, jaccard_score, hamming_loss\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "# code_smells = ['CDSBP','CC','LC','LZC','RB','SC']\n",
        "\n",
        "# for smell in code_smells:\n",
        "\n",
        "#   # Caricamento del tokenizer e del modello pre-addestrato CodeBERT\n",
        "#   model = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\", num_labels=1)\n",
        "#   tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")\n",
        "\n",
        "#   # Creazione X e y. X = dataset senza le etichette, y = etichette\n",
        "#   dataframe2 = dataframe.drop(columns=['CDSBP','CC','LC','LZC','RB','SC'])\n",
        "#   y = dataframe[str(smell)]\n",
        "\n",
        "#   # Divisione in train, validation e test set\n",
        "#   X_train, X_val_test, Y_train, Y_val_test = train_test_split(dataframe2, y, test_size=0.4, random_state=1)\n",
        "#   X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size=0.5, random_state=1)\n",
        "#   # Tokenizzazione del set di addestramento\n",
        "#   train_encodings = tokenizer(list(X_train['Component']), truncation=True, padding=True, max_length = 1024)\n",
        "#   train_labels = pt.tensor(Y_train.values)\n",
        "\n",
        "#   # Tokenizzazione del set di validazione\n",
        "#   val_encodings = tokenizer(list(X_val['Component']), truncation=True, padding=True, max_length = 1024)\n",
        "#   val_labels = pt.tensor(Y_val.values)\n",
        "\n",
        "#   # Tokenizzazione del set di test\n",
        "#   test_encodings = tokenizer(list(X_test['Component']), truncation=True, padding=True, max_length = 1024)\n",
        "#   test_labels = pt.tensor(Y_test.values)\n",
        "\n",
        "\n",
        "#   device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "#   # Creazione del dataset di addestramento e validazione\n",
        "#   train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), train_labels)\n",
        "#   val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']), val_labels)\n",
        "\n",
        "#   # Creazione dei dataloader\n",
        "#   batch_size = 4\n",
        "#   train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "#   val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "#   # Creazione del modello\n",
        "#   model.to(device)\n",
        "#   model.train()\n",
        "\n",
        "#   # Impostazione dell'ottimizzatore\n",
        "#   optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "#   # Definizione della funzione di perdita\n",
        "#   loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "#   # Addestramento del modello\n",
        "#   for epoch in range(3):\n",
        "#       for batch in train_dataloader:\n",
        "#           optimizer.zero_grad()\n",
        "#           inputs = batch[0].to(device)\n",
        "#           labels = batch[1].to(device)\n",
        "\n",
        "#           outputs = model(inputs)\n",
        "#           logits = outputs.last_hidden_state[:, 0, :]\n",
        "\n",
        "#           loss = loss_function(logits, labels)\n",
        "#           loss.backward()\n",
        "#           optimizer.step()\n",
        "\n",
        "#           print(f\"Epoch {epoch+1} - Loss: {loss.item()}\")\n",
        "\n",
        "#           # Liberazione memoria GPU\n",
        "#           del inputs, labels\n",
        "#           torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "\n",
        "#   val_accuracy = 0\n",
        "#   precision_avg = 0\n",
        "#   jaccard_score_avg = 0\n",
        "#   hamming_loss_score = 0\n",
        "#   total_val_samples = len(val_dataloader.dataset)\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#       for batch in val_dataloader:\n",
        "#           inputs = batch[0].to(device)\n",
        "#           labels = batch[1].to(device)\n",
        "\n",
        "#           val_outputs = model(inputs)\n",
        "#           # print(val_outputs)\n",
        "#           val_predicted_labels = torch.argmax(val_outputs.pooler_output, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "#           val_accuracy = accuracy_score(labels.cpu().numpy(), val_predicted_labels.cpu().numpy())\n",
        "#           precision_avg = precision_score(labels.cpu().numpy(), val_predicted_labels.cpu().numpy(), average='macro')\n",
        "\n",
        "\n",
        "#           jaccard_score_avg += jaccard_score(labels.cpu().numpy(), val_predicted_labels.cpu().numpy(), average='macro')\n",
        "#           hamming_loss_score += hamming_loss(labels.cpu().numpy(), val_predicted_labels.cpu().numpy())\n",
        "\n",
        "#           # Libera la memoria GPU\n",
        "#           del inputs, labels, val_outputs, val_predicted_labels\n",
        "#           torch.cuda.empty_cache()\n",
        "\n",
        "#   val_accuracy /= total_val_samples\n",
        "#   precision_avg /= total_val_samples\n",
        "#   jaccard_score_avg /= total_val_samples\n",
        "#   hamming_loss_score /= total_val_samples\n",
        "\n",
        "#   print(f\"Validation Accuracy: {val_accuracy}\")\n",
        "#   print(f\"Precision: {precision_avg}\")\n",
        "#   print(f\"Jaccard Score: {jaccard_score_avg}\")\n",
        "#   print(f\"Hamming Loss: {hamming_loss_score}\")\n",
        "\n",
        "\n",
        "\n",
        "#   # Calcola le predizioni del modello sul dataset di validazione\n",
        "#   model.eval()\n",
        "#   with torch.no_grad():\n",
        "#       predicted_labels = []\n",
        "#       true_labels = []\n",
        "#       for batch in val_dataloader:\n",
        "#           inputs = batch[0].to(device)\n",
        "#           labels = batch[1].to(device)\n",
        "#           outputs = model(inputs)\n",
        "#           predicted_labels.extend(outputs.logits.sigmoid().round().cpu().numpy())\n",
        "#           true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "#   # Calcola la matrice di confusione\n",
        "#   confusion_matrix = multilabel_confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "#   # Etichette delle classi\n",
        "#   class_labels = ['CDSBP', 'CC', 'LC', 'LZC', 'RB', 'SC']\n",
        "\n",
        "#   # Visualizza la matrice di confusione\n",
        "#   plt.figure(figsize=(10, 8))\n",
        "#   for i, cm in enumerate(confusion_matrix):\n",
        "#       plt.subplot(2, 3, i + 1)\n",
        "#       sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "#       plt.xlabel('Etichetta predetta')\n",
        "#       plt.ylabel('Etichetta reale')\n",
        "#       plt.title(f'Matrice di confusione - {class_labels[i]}')\n",
        "#   plt.tight_layout()\n",
        "#   plt.show()"
      ],
      "metadata": {
        "id": "9kAU0645rvqA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}