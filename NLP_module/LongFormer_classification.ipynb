{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ID7T5RDUhHSd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684517370332,"user_tz":-120,"elapsed":2347,"user":{"displayName":"Dario De Maio","userId":"00570986716446117962"}},"outputId":"34441f55-6273-4900-99f7-71ac14c02289"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dIPMET94jBPC","executionInfo":{"status":"ok","timestamp":1684517380129,"user_tz":-120,"elapsed":9803,"user":{"displayName":"Dario De Maio","userId":"00570986716446117962"}},"outputId":"2a8a9c3c-c680-4186-e5ba-d4d9e2bfdf2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install torch\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZahQ0GsPqM-Z","executionInfo":{"status":"ok","timestamp":1684517393087,"user_tz":-120,"elapsed":12962,"user":{"displayName":"Dario De Maio","userId":"00570986716446117962"}},"outputId":"7fbcee32-63ac-41bb-9e4f-0b5d911d8a13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import pandas as pd\n","from transformers import LongformerModel, AutoTokenizer\n","import torch as pt\n","from sklearn.model_selection import train_test_split\n","import os\n","import numpy as np\n","import chardet\n","from sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix\n","import seaborn as sns\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"],"metadata":{"id":"wkQ0Sz5OjCjB","executionInfo":{"status":"error","timestamp":1684517399111,"user_tz":-120,"elapsed":528,"user":{"displayName":"Dario De Maio","userId":"00570986716446117962"}},"colab":{"base_uri":"https://localhost:8080/","height":519},"outputId":"3b5ef61e-fc6c-4a3c-f094-7fb2bfcc4736"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-0fc983c9ab40>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLongformerModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from .utils import (\n\u001b[1;32m     28\u001b[0m     \u001b[0mOptionalDependencyNotAvailable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdependency_versions_table\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequire_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_version_core\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mreplace_return_docstrings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n\u001b[0;32m---> 30\u001b[0;31m from .generic import (\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mContextManagers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mExplicitEnum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimport_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_flax_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_tf_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_torch_fx_proxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpackaging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib_metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/logging.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauto\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtqdm_lib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mtqdm_stream_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m )\n\u001b[0;32m---> 91\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_telemetry\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msend_telemetry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_telemetry.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_hf_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'logging' from 'huggingface_hub' (/usr/local/lib/python3.10/dist-packages/huggingface_hub/__init__.py)","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["# Caricamento del tokenizer e del modello pre-addestrato CodeBERT\n","model = LongformerModel.from_pretrained(\"allenai/longformer-base-4096\")\n","tokenizer = AutoTokenizer.from_pretrained(\"allenai/longformer-base-4096\")"],"metadata":{"id":"g3-JptpCjeAL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe = pd.read_csv(\"drive/MyDrive/Colab Notebooks/code smells tesi/Code_Smells_NLP-1/dataset/final_dataset.csv\")\n"],"metadata":{"id":"rJsU045KjhJ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dataframe"],"metadata":{"id":"U2HSfOwej7hk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import nltk\n","import re\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","stop_words = set(stopwords.words('italian'))\n","\n","def remove_comments(code):\n","    # Rimuove i commenti su una singola riga\n","    code = re.sub(r'//.*', '', code)\n","    # Rimuove i commenti su più righe\n","    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n","    # Rimuove le stopwords\n","    tokens = [word.lower() for word in code.split() if word.lower() not in stop_words]\n","    filtered_text = ' '.join(tokens)\n","    # Rimuoviamo gli import\n","    code = re.sub(r'import\\s+.*?;', '', code, flags=re.DOTALL)\n","    # Rimuoviamo i package\n","    code = re.sub(r'package\\s+.*?;', '', code, flags=re.DOTALL)\n","    #Rimuove \\n e \\t\n","    code = re.sub(r'[\\n\\t]', '', code)\n","    return code\n","\n","for i in range(len(dataframe)):\n","    dataframe['Component'][i] = remove_comments(dataframe['Component'][i])"],"metadata":{"id":"qq1FfqzUXeZJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creazione X e y. X = dataset senza le etichette, y = etichette\n","dataframe2 = dataframe.drop(columns=['CDSBP','CC','LC','LZC','RB','SC'])\n","y = dataframe[['CDSBP','CC','LC','LZC','RB','SC']]"],"metadata":{"id":"W53vQRE5kEYi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divisione in train, validation e test set\n","X_train, X_val_test, Y_train, Y_val_test = train_test_split(dataframe2, y, test_size=0.4, random_state=1)\n","X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size=0.5, random_state=1)"],"metadata":{"id":"8oNVSnQNkHLp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizzazione del set di addestramento\n","train_encodings = tokenizer(list(X_train['Component']), truncation=True, padding=True, max_length = 1024)\n","train_labels = pt.tensor(Y_train.values)\n","\n","# Tokenizzazione del set di validazione\n","val_encodings = tokenizer(list(X_val['Component']), truncation=True, padding=True, max_length = 1024)\n","val_labels = pt.tensor(Y_val.values)\n","\n","# Tokenizzazione del set di test\n","test_encodings = tokenizer(list(X_test['Component']), truncation=True, padding=True, max_length = 1024)\n","test_labels = pt.tensor(Y_test.values)"],"metadata":{"id":"c0i1eE6IpnBp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"3Ew9D_t0zxSK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from transformers import AdamW\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn as nn\n","\n","# Creazione del dataset di addestramento e validazione\n","train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']), train_labels)\n","val_dataset = TensorDataset(torch.tensor(val_encodings['input_ids']), val_labels)\n","\n","# Creazione dei dataloader\n","batch_size = 4\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# Creazione del modello\n","model.to(device)\n","model.train()\n","\n","# Impostazione dell'ottimizzatore\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","\n","# Definizione della funzione di perdita\n","loss_function = nn.CrossEntropyLoss()\n","\n","# Addestramento del modello\n","for epoch in range(10):\n","    for batch in train_dataloader:\n","        optimizer.zero_grad()\n","        inputs = batch[0].to(device)\n","        labels = batch[1].to(device)\n","\n","        outputs = model(inputs)\n","        logits = outputs.last_hidden_state[:, 0, :]\n","\n","        # Modifica delle etichette in tensor 1D\n","        labels = torch.argmax(labels, dim=1)\n","\n","        loss = loss_function(logits, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f\"Epoch {epoch+1} - Loss: {loss.item()}\")\n","\n","        # Liberazione memoria GPU\n","        del inputs, labels\n","        torch.cuda.empty_cache()"],"metadata":{"id":"FuiNq4kEqjCw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","from sklearn.metrics import accuracy_score, precision_score, jaccard_score, hamming_loss\n","\n","val_accuracy = 0\n","total_val_samples = 0\n","precision_avg = 0\n","jaccard_score_avg = 0\n","hamming_loss_score = 0\n","\n","for batch in val_dataloader:\n","    inputs = batch[0].to(device)\n","    labels = batch[1].to(device)\n","\n","    val_outputs = model(inputs)\n","    val_predicted_labels = (val_outputs.pooler_output.sigmoid() > 0.5).int()  # Utilizza pooler_output invece di logits\n","    \n","    val_accuracy += (val_predicted_labels == labels).sum().item()\n","    precision_avg += precision_score(labels.cpu().numpy(), val_predicted_labels.cpu().numpy(), average='samples')\n","    jaccard_score_avg += jaccard_score(labels.cpu().numpy(), val_predicted_labels.cpu().numpy(), average='samples')\n","    hamming_loss_score += hamming_loss(labels.cpu().numpy(), val_predicted_labels.cpu().numpy())\n","    \n","    total_val_samples += len(inputs)\n","    # Libera la memoria GPU\n","    del inputs, labels, val_outputs, val_predicted_labels\n","    torch.cuda.empty_cache()\n","\n","val_accuracy /= total_val_samples\n","precision_avg /= total_val_samples\n","jaccard_score_avg /= total_val_samples\n","hamming_loss_score /= total_val_samples\n","\n","print(f\"Validation Accuracy: {val_accuracy}\")\n","print(f\"Precision: {precision_avg}\")\n","print(f\"Jaccard Score: {jaccard_score_avg}\")\n","print(f\"Hamming Loss: {hamming_loss_score}\")\n"],"metadata":{"id":"BYS_2o3mhE3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import multilabel_confusion_matrix\n","\n","# Calcola le predizioni del modello sul dataset di validazione\n","model.eval()\n","with torch.no_grad():\n","    predicted_labels = []\n","    true_labels = []\n","    for batch in val_dataloader:\n","        inputs = batch[0].to(device)\n","        labels = batch[1].to(device)\n","        outputs = model(inputs)\n","        predicted_labels.extend(outputs.logits.sigmoid().round().cpu().numpy())\n","        true_labels.extend(labels.cpu().numpy())\n","\n","# Calcola la matrice di confusione\n","confusion_matrix = multilabel_confusion_matrix(true_labels, predicted_labels)\n","\n","# Etichette delle classi\n","class_labels = ['CDSBP', 'CC', 'LC', 'LZC', 'RB', 'SC']\n","\n","# Visualizza la matrice di confusione\n","plt.figure(figsize=(10, 8))\n","for i, cm in enumerate(confusion_matrix):\n","    plt.subplot(2, 3, i + 1)\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n","    plt.xlabel('Etichetta predetta')\n","    plt.ylabel('Etichetta reale')\n","    plt.title(f'Matrice di confusione - {class_labels[i]}')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"30rKNpX1lKrF"},"execution_count":null,"outputs":[]}]}